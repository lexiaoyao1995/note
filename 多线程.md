[TOC]

* [概念](#%E6%A6%82%E5%BF%B5)
    * [死锁](#%E6%AD%BB%E9%94%81)
      * [四个基本条件](#%E5%9B%9B%E4%B8%AA%E5%9F%BA%E6%9C%AC%E6%9D%A1%E4%BB%B6)
      * [避免死锁](#%E9%81%BF%E5%85%8D%E6%AD%BB%E9%94%81)
        * [死锁预防](#%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2)
        * [避免死锁](#%E9%81%BF%E5%85%8D%E6%AD%BB%E9%94%81-1)
        * [死锁检测与解除](#%E6%AD%BB%E9%94%81%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%A7%A3%E9%99%A4)
    * [机制](#%E6%9C%BA%E5%88%B6)
      * [threadlocal](#threadlocal)
        * [ThreadLocal 如何保证Local属性？](#threadlocal-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81local%E5%B1%9E%E6%80%A7)
        * [如何自己实现一个ThreadLocal](#%E5%A6%82%E4%BD%95%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AAthreadlocal)
      * [fork/join](#forkjoin)
    * [线程](#%E7%BA%BF%E7%A8%8B)
    * [CAS](#cas)
    * [synchronized](#synchronized)
    * [AQS](#aqs)
    * [线程池](#%E7%BA%BF%E7%A8%8B%E6%B1%A0)
      * [execute和submit区别](#execute%E5%92%8Csubmit%E5%8C%BA%E5%88%AB)
      * [6、读写锁适用于什么场景](#6%E8%AF%BB%E5%86%99%E9%94%81%E9%80%82%E7%94%A8%E4%BA%8E%E4%BB%80%E4%B9%88%E5%9C%BA%E6%99%AF)
      * [10、thraedLocal用来解决什么问题](#10thraedlocal%E7%94%A8%E6%9D%A5%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98)
* [线程基础](#%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80)
    * [yield](#yield)
    * [如何中断线程](#%E5%A6%82%E4%BD%95%E4%B8%AD%E6%96%AD%E7%BA%BF%E7%A8%8B)
    * [线程安全问题的主要诱因](#%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%BB%E8%A6%81%E8%AF%B1%E5%9B%A0)
* [JUC分类](#juc%E5%88%86%E7%B1%BB)
      * [并发工具类](#%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB)
        * [1、闭锁 CountDownLatch](#1%E9%97%AD%E9%94%81-countdownlatch)
        * [2、栅栏 CyclicBarrier](#2%E6%A0%85%E6%A0%8F-cyclicbarrier)
        * [3、信号量 Semaphore](#3%E4%BF%A1%E5%8F%B7%E9%87%8F-semaphore)
        * [4、交换器 Exchanger](#4%E4%BA%A4%E6%8D%A2%E5%99%A8-exchanger)
* [synchronized](#synchronized-1)
    * [synchronized互斥锁的特性](#synchronized%E4%BA%92%E6%96%A5%E9%94%81%E7%9A%84%E7%89%B9%E6%80%A7)
    * [根据获取的锁的分类：获取对象锁和获取类锁](#%E6%A0%B9%E6%8D%AE%E8%8E%B7%E5%8F%96%E7%9A%84%E9%94%81%E7%9A%84%E5%88%86%E7%B1%BB%E8%8E%B7%E5%8F%96%E5%AF%B9%E8%B1%A1%E9%94%81%E5%92%8C%E8%8E%B7%E5%8F%96%E7%B1%BB%E9%94%81)
    * [对象锁和类锁的总结](#%E5%AF%B9%E8%B1%A1%E9%94%81%E5%92%8C%E7%B1%BB%E9%94%81%E7%9A%84%E6%80%BB%E7%BB%93)
    * [synchronized底层实现原理](#synchronized%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86)
      * [实现synchronized基础](#%E5%AE%9E%E7%8E%B0synchronized%E5%9F%BA%E7%A1%80)
      * [对象在内存中的布局](#%E5%AF%B9%E8%B1%A1%E5%9C%A8%E5%86%85%E5%AD%98%E4%B8%AD%E7%9A%84%E5%B8%83%E5%B1%80)
    * [monitor](#monitor)
    * [synchronized是可重入锁](#synchronized%E6%98%AF%E5%8F%AF%E9%87%8D%E5%85%A5%E9%94%81)
    * [synchronized的优化](#synchronized%E7%9A%84%E4%BC%98%E5%8C%96)
      * [自旋锁   PreBlockSpin](#%E8%87%AA%E6%97%8B%E9%94%81---preblockspin)
      * [自适应自旋锁](#%E8%87%AA%E9%80%82%E5%BA%94%E8%87%AA%E6%97%8B%E9%94%81)
      * [锁消除](#%E9%94%81%E6%B6%88%E9%99%A4)
      * [锁粗化](#%E9%94%81%E7%B2%97%E5%8C%96)
    * [synchronized的四种状态](#synchronized%E7%9A%84%E5%9B%9B%E7%A7%8D%E7%8A%B6%E6%80%81)
        * [偏向锁](#%E5%81%8F%E5%90%91%E9%94%81)
        * [轻量锁](#%E8%BD%BB%E9%87%8F%E9%94%81)
        * [重量级锁](#%E9%87%8D%E9%87%8F%E7%BA%A7%E9%94%81)
* [ReentrantLock（再入锁）](#reentrantlock%E5%86%8D%E5%85%A5%E9%94%81)
        * [公平性设置](#%E5%85%AC%E5%B9%B3%E6%80%A7%E8%AE%BE%E7%BD%AE)
        * [ReentrantLock将锁对象化](#reentrantlock%E5%B0%86%E9%94%81%E5%AF%B9%E8%B1%A1%E5%8C%96)
        * [wait、notify notifyAll  Condition](#waitnotify-notifyall--condition)
    * [读写锁和copyOnWrite](#%E8%AF%BB%E5%86%99%E9%94%81%E5%92%8Ccopyonwrite)
      * [读写锁（ReentrantReadWriteLock）](#%E8%AF%BB%E5%86%99%E9%94%81reentrantreadwritelock)
      * [copyOnWrite](#copyonwrite)
    * [AQS  是ReentantLock的底层](#aqs--%E6%98%AFreentantlock%E7%9A%84%E5%BA%95%E5%B1%82)
    * [Q:谈谈对于AQS的理解](#q%E8%B0%88%E8%B0%88%E5%AF%B9%E4%BA%8Eaqs%E7%9A%84%E7%90%86%E8%A7%A3)
      * [1、概念](#1%E6%A6%82%E5%BF%B5)
      * [2、框架](#2%E6%A1%86%E6%9E%B6)
        * [ReentrantLock和synchronized的区别](#reentrantlock%E5%92%8Csynchronized%E7%9A%84%E5%8C%BA%E5%88%AB)
* [原子类](#%E5%8E%9F%E5%AD%90%E7%B1%BB)
    * [AtomicInteger](#atomicinteger)
    * [LongAdder](#longadder)
* [volatile](#volatile)
    * [指令重排序需要满足的条件](#%E6%8C%87%E4%BB%A4%E9%87%8D%E6%8E%92%E5%BA%8F%E9%9C%80%E8%A6%81%E6%BB%A1%E8%B6%B3%E7%9A%84%E6%9D%A1%E4%BB%B6)
    * [happens\-before](#happens-before)
    * [volatile ：jvm提供的轻量级同步机制](#volatile-jvm%E6%8F%90%E4%BE%9B%E7%9A%84%E8%BD%BB%E9%87%8F%E7%BA%A7%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6)
    * [volatile变量为何立即可见](#volatile%E5%8F%98%E9%87%8F%E4%B8%BA%E4%BD%95%E7%AB%8B%E5%8D%B3%E5%8F%AF%E8%A7%81)
    * [volatile如何禁止重排优化](#volatile%E5%A6%82%E4%BD%95%E7%A6%81%E6%AD%A2%E9%87%8D%E6%8E%92%E4%BC%98%E5%8C%96)
* [java线程池](#java%E7%BA%BF%E7%A8%8B%E6%B1%A0)
    * [利用Executors创建不同的线程池满足不同场景的需求](#%E5%88%A9%E7%94%A8executors%E5%88%9B%E5%BB%BA%E4%B8%8D%E5%90%8C%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BB%A1%E8%B6%B3%E4%B8%8D%E5%90%8C%E5%9C%BA%E6%99%AF%E7%9A%84%E9%9C%80%E6%B1%82)
    * [为什么要使用线程池子](#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AD%90)
    * [juc的三个executor接口](#juc%E7%9A%84%E4%B8%89%E4%B8%AAexecutor%E6%8E%A5%E5%8F%A3)
    * [ThreadPoolExecutor的构造函数](#threadpoolexecutor%E7%9A%84%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0)
    * [handler：线程饱和策列](#handler%E7%BA%BF%E7%A8%8B%E9%A5%B1%E5%92%8C%E7%AD%96%E5%88%97)
    * [新任务提交execute执行后的判断](#%E6%96%B0%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4execute%E6%89%A7%E8%A1%8C%E5%90%8E%E7%9A%84%E5%88%A4%E6%96%AD)
    * [线程池的状态](#%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E7%8A%B6%E6%80%81)
    * [线程池大小选择](#%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%A4%A7%E5%B0%8F%E9%80%89%E6%8B%A9)
    * [对于query的选择，以及排队的策略](#%E5%AF%B9%E4%BA%8Equery%E7%9A%84%E9%80%89%E6%8B%A9%E4%BB%A5%E5%8F%8A%E6%8E%92%E9%98%9F%E7%9A%84%E7%AD%96%E7%95%A5)
    * [拒绝服务策略](#%E6%8B%92%E7%BB%9D%E6%9C%8D%E5%8A%A1%E7%AD%96%E7%95%A5)
* [CAS](#cas-1)
    * [Q:什么是CAS](#q%E4%BB%80%E4%B9%88%E6%98%AFcas)
    * [Unsafe类](#unsafe%E7%B1%BB)
      * [和CAS相关的API](#%E5%92%8Ccas%E7%9B%B8%E5%85%B3%E7%9A%84api)
      * [Atomic类的底层就是通过Unsafe实现的，思路是CAS](#atomic%E7%B1%BB%E7%9A%84%E5%BA%95%E5%B1%82%E5%B0%B1%E6%98%AF%E9%80%9A%E8%BF%87unsafe%E5%AE%9E%E7%8E%B0%E7%9A%84%E6%80%9D%E8%B7%AF%E6%98%AFcas)
    * [CAS的ABA问题及其解决方法](#cas%E7%9A%84aba%E9%97%AE%E9%A2%98%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95)
      * [解决方法](#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95)

# 概念

![](pic/爱奇艺20190709111017.png)

### 死锁

#### 四个基本条件

    1、互斥：某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结束。
    2、占有且等待：一个进程本身占有资源（一种或多种），同时还有资源未得到满足，正在等待其他进程释放该资源。
    3、不可抢占：别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来。
    4、循环等待：存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源。
       当以上四个条件均满足，必然会造成死锁，发生死锁的进程无法进行下去，它们所持有的资源也无法释放。这样会导致CPU的吞吐量下降。所以死锁情况是会浪费系统资源和影响计算机的使用性能的。那么，解决死锁问题就是相当有必要的了。
#### 避免死锁

##### 死锁预防

 产生死锁需要四个条件，那么，只要这四个条件中至少有一个条件得不到满足，就不可能发生死锁了。由于互斥条件是非共享资源所必须的，不仅不能改变，还应加以保证，所以，主要是破坏产生死锁的其他三个条件。

a、破坏“占有且等待”条件
     方法1：所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源。
         优点：简单易实施且安全。
         缺点：因为某项资源不满足，进程无法启动，而其他已经满足了的资源也不会得到利用，严重降低了资源的利用率，造成资源浪费。
                  使进程经常发生饥饿现象。
     方法2：该方法是对第一种方法的改进，允许进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放掉分配到的已经使用完毕的资源，然后再去请求新的资源。这样的话，资源的利用率会得到提高，也会减少进程的饥饿问题。
b、破坏“不可抢占”条件
      当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请。这就意味着进程已占有的资源会被短暂地释放或者说是被抢占了。
      该种方法实现起来比较复杂，且代价也比较大。释放已经保持的资源很有可能会导致进程之前的工作实效等，反复的申请和释放资源会导致进程的执行被无限的推迟，这不仅会延长进程的周转周期，还会影响系统的吞吐量。
c、破坏“循环等待”条件
     可以通过定义资源类型的线性顺序来预防，可将每个资源编号，当一个进程占有编号为i的资源时，那么它下一次申请资源只能申请编号大于i的资源。

##### 避免死锁

死锁避免是利用额外的检验信息，在分配资源时判断是否会出现死锁，只在不会出现死锁的情况下才分配资源。

两种避免办法：

​    1、如果一个进程的请求会导致死锁，则不启动该进程

​    2、如果一个进程的增加资源请求会导致死锁 ，则拒绝该申请。

避免死锁的具体实现通常利用银行家算法

银行家算法通过对进程需求、占有和系统拥有资源的实时统计，确保系统在分配给进程资源不会造成死锁才会给与分配。
死锁避免的优点：不需要死锁预防中的抢占和重新运行进程，并且比死锁预防的限制要少。
死锁避免的限制：
    必须事先声明每个进程请求的最大资源量
    考虑的进程必须无关的，也就是说，它们执行的顺序必须没有任何同步要求的限制
    分配的资源数目必须是固定的。
    在占有资源时，进程不能退出

##### 死锁检测与解除

如果利用死锁检测算法检测出系统已经出现了死锁 ，那么，此时就需要对系统采取相应的措施。常用的解除死锁的方法：

1、抢占资源：从一个或多个进程中抢占足够数量的资源分配给死锁进程，以解除死锁状态。

2、终止（或撤销）进程：终止或撤销系统中的一个或多个死锁进程，直至打破死锁状态。


### 机制

#### threadlocal

线程独享的数据

**用法**

1、ThreadLocal.get: 获取ThreadLocal中当前线程共享变量的值。

2、ThreadLocal.set: 设置ThreadLocal中当前线程共享变量的值。

3、ThreadLocal.remove: 移除ThreadLocal中当前线程共享变量的值。

4、ThreadLocal.initialValue: ThreadLocal没有被当前线程赋值时或当前线程刚调用remove方法后调用get方法，返回此方法值。

**实现机制**

使用弱引用的threadlocalMap

~~~java
static class Entry extends WeakReference<ThreadLocal> {
            /** The value associated with this ThreadLocal. */
            Object value;

            Entry(ThreadLocal k, Object v) {
                super(k);
                value = v;
            }
        }

~~~

Entry 是一个包含 key 和 value 的一个对象，Entry的key为ThreadLocal，value为ThreadLocal对应的值，只不过是对这个Entry做了一些特殊处理，即 使用 `WeakReference<ThreadLocal>`将 `ThreadLocal`对象变成一个弱引用的对象，这样做的好处就是在线程销毁的时候，对应的实体就会被回收，不会出现内存泄漏。

##### ThreadLocal 如何保证Local属性？

当需要使用多线程时，有个变量恰巧不需要共享，此时就不必使用synchronized这么麻烦的关键字来锁住，每个线程都相当于在堆内存中开辟一个空间，线程中带有对共享变量的缓冲区，通过缓冲区将堆内存中的共享变量进行读取和操作，ThreadLocal相当于线程内的内存，一个局部变量。每次可以对线程自身的数据读取和操作，并不需要通过缓冲区与 主内存中的变量进行交互。并不会像synchronized那样修改主内存的数据，再将主内存的数据复制到线程内的工作内存。ThreadLocal可以让线程独占资源，存储于线程内部，避免线程堵塞造成CPU吞吐下降。

在每个Thread中包含一个ThreadLocalMap，ThreadLocalMap的key是ThreadLocal的对象，value是独享数据。

##### 如何自己实现一个ThreadLocal

用一个线程安全的map来模拟ThreadLocalMap

~~~java
public class SimpleThreadLocal<T>{
    /**
     * Key为线程对象，Value为传入的值对象
     */
    private Map<Thread, T> valueMap = Collections.synchronizedMap(new HashMap<Thread, T>());

    /**
     * 设值
     * @param value Map键值对的value
     */
    public void set(T value) {
        valueMap.put(Thread.currentThread(), value);
    }

    /**
     * 取值
     * @return
     */
    public T get() {
        Thread currentThread = Thread.currentThread();
        //返回当前线程对应的变量
        T t = valueMap.get(currentThread);
        //如果当前线程在Map中不存在，则将当前线程存储到Map中
        if (t == null && !valueMap.containsKey(currentThread)) {
            t = initialValue();
            valueMap.put(currentThread, t);
        }
        return t;
    }

    public void remove() {
        valueMap.remove(Thread.currentThread());
    }

    public T initialValue() {
        return null;
    }
~~~



#### fork/join

大任务的分割与汇总

工作窃取算法

### 线程

线程是jvm执行任务的最小单元

![](pic/爱奇艺20190709111401.png)

### CAS

![](pic/爱奇艺20190709111648.png)

### synchronized

![](pic/爱奇艺20190709112022.png)

synchronized是对对象进行加锁，在jvm中，对象在内存中分为三块区域，对象头，实例数据，和对齐填充，在对象头中保留了锁标志位和指向monitor对象的起始地址，当monitor被某个线程占用后，就会处于锁定状态，monitor中的owner部分会指向持有monitor的线程，monitor还有两个队列用于存放进入以及等待锁的线程

synchronized应用在方法上时，是通过字节码ACC_synchronized实现的

synchronized应用在同步块时，是通过字节码monitorenter和monitorexit实现的

针对synchronized获取锁的方式，jvm通过锁升级的方式优化锁，偏向锁，轻量锁，重量级锁

### AQS

![](pic/爱奇艺20190709112802.png)

队列同步器（AQS）是实现lock的基础

### 线程池

#### execute和submit区别

submit会返回一个future对象，可以取消任务的执行，还可以获取执行结果或是执行异常

![](pic/爱奇艺20190709113054.png)

![](pic/爱奇艺20190709113231.png)

![](pic/爱奇艺20190709113553.png)

![](pic/爱奇艺20190709114613.png)

![](pic/爱奇艺20190709114756.png)

![](pic/爱奇艺20190709114947.png)

![](pic/爱奇艺20190709115602.png)

![](pic/爱奇艺20190709115924.png)

![](pic/爱奇艺20190709120044.png)

#### 6、读写锁适用于什么场景

适用于读并发多，写并发少的场景，或使用copyOnwrite

![](pic/爱奇艺20190709130352.png)

#### 10、thraedLocal用来解决什么问题

threadLocal不是用来解决线程共享变量问题，而是用来解决线程数据隔离问题

# 线程基础

### yield

概念：

当调用Thread.yield()函数时，会给线程调度器一个当前线程愿意让出CPU使用的暗示，但是线程调度器可能会忽略这个暗示。

### 如何中断线程

目前使用的方法

调用interrupt()，，通知线程应该中断了

1、如果线程处于被阻塞状态，那么线程将立即退出被阻塞状态，并抛出一个IntertuptedException异常

2、如果线程处于正常活动状态，那么会将该线程的中断标志设置为true，被设置中断标志的线程将继续正常运行。

3、需要被调用的线程配合中断

在正常运行任务时，经常检查本线程的中断标记位，如果被设置了中断标记就自动停止线程00000

### 线程安全问题的主要诱因

1、存在共享数据

2、存在多条线程共同操作这些共享数据

解决问题的根本方法：

同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再对共享数据进行操作。

# JUC分类

1、线程执行器executor

2、锁locks

3、原子变量类atomic

4、并发工具类tools

5、并发集合collections

#### 并发工具类

##### 1、闭锁 CountDownLatch

让主线程等待一组事件发生后继续执行

CountDownLatch是通过一个计数器来实现的，计数器的初始值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就会减1。当计数器值到达0时，它表示所有的线程已经完成了任务，然后在闭锁上等待的线程就可以恢复执行任务。

~~~java
countDownLatch.countDown() //计数器减一
countDownLatch.await();  //线程等待，直到计数器为0
~~~

~~~java
package demo;

import java.util.concurrent.CountDownLatch;

public class Thread1 implements Runnable {

    private CountDownLatch countDownLatch;

    public Thread1(CountDownLatch countDownLatch) {
        this.countDownLatch = countDownLatch;
    }

    @Override
    public void run() {
        try {
            System.out.println("线程1执行");
            Thread.sleep(500);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }finally {
            countDownLatch.countDown();
        }

    }
     public static void main(String[] args) throws InterruptedException {
        CountDownLatch countDownLatch = new CountDownLatch(2);
        ExecutorService executorService = Executors.newFixedThreadPool(2);
        executorService.execute(new Thread1(countDownLatch));
        executorService.execute(new Thread1(countDownLatch));
        countDownLatch.await();
        System.out.println("等待结束");

    }
}

~~~



##### 2、栅栏 CyclicBarrier

阻塞当前线程，等待其他线程

等待其他线程，且会阻塞自己当前线程，所有线程必须同时达到栅栏位置后，才能继续执行

所有线程达到栅栏处，可以触发执行另外一个预先设置好的线程

~~~java
package demo;

import java.util.concurrent.CyclicBarrier;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class CyclicBarrierDemo {

    static class TaskThread extends Thread {

        CyclicBarrier cyclicBarrier;

        public TaskThread(CyclicBarrier cyclicBarrier) {
            this.cyclicBarrier = cyclicBarrier;
        }

        @Override
        public void run() {
            try {
                while (true){
                    System.out.println(getName() + "到达栅栏");
                    cyclicBarrier.await();//当参与线程的个数达到数量后，会继续执行
                }
//                Thread.sleep(2000);
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
    }

    public static void main(String[] args) {
        int threadNum = 5;
        ExecutorService executorService = Executors.newCachedThreadPool();
        CyclicBarrier cyclicBarrier = new CyclicBarrier(threadNum, () -> {
            System.out.println("最后的任务");//这个参数的意思是最后一个到达线程要做的任务
        });
        for (int i = 0; i < threadNum; i++) {
            new TaskThread(cyclicBarrier).start();
        }
        executorService.shutdown();
    }

}

~~~

**CyclicBarrier 与 CountDownLatch 区别**

- CountDownLatch 是一次性的，CyclicBarrier 是可循环利用的
- CountDownLatch 参与的线程的职责是不一样的，有的在倒计时，有的在等待倒计时结束。CyclicBarrier 参与的线程职责是一样的。

##### 3、信号量 Semaphore

控制某个资源可被同时访问的线程个数

~~~java
package demo;

import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;

public class SemaphoreDemo {

    private static Semaphore semaphore = new Semaphore(5, true);//最多五个线程获取到资源

    public static void main(String[] args) {
        ExecutorService service = Executors.newFixedThreadPool(10);
        // 10个学生
        for (int i = 0; i < 10; i++) {
            service.execute(() -> {
                try {
                    System.out.println(Thread.currentThread().getName() + " 同学想要拿到笔===");
                    semaphore.acquire();//获取
                    System.out.println(Thread.currentThread().getName() + " 同学拿到笔---");
                    System.out.println(Thread.currentThread().getName() + " 同学填写中...");
                    TimeUnit.SECONDS.sleep(2);
                    System.out.println(Thread.currentThread().getName() + " 同学填写完毕，马上归还笔。。。");
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    semaphore.release();//释放
                }
            });
        }
        service.shutdown();
    }


}

~~~



##### 4、交换器 Exchanger

两个线程到达同步点后，相互交换数据

用来支持**两个线程**之间交换数据,不支持更多线程 

~~~java
public class ExchangerDemo {

    public static void main(String[] args) {
        Exchanger<Object> exchanger = new Exchanger<>();

        new Thread(() -> {
            Object object = new Object();
            System.out.println(Thread.currentThread().getName() + "创建的对象是" + object);
            try {
                object = exchanger.exchange(object);//交换点，阻塞
                System.out.println(Thread.currentThread().getName() + "交换后得到的对象是" + object);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }, "线程1").start();

        new Thread(() -> {
            Object object = new Object();
            System.out.println(Thread.currentThread().getName() + "创建的对象是" + object);
            try {
                TimeUnit.SECONDS.sleep(2);
                object = exchanger.exchange(object);
                System.out.println(Thread.currentThread().getName() + "交换后得到的对象是" + object);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }, "线程2").start();
    }

}
~~~





# synchronized

### synchronized互斥锁的特性

1、互斥性：即在同一时刻只允许一个线程持有某个对象锁，通过这种特性来实现多线程的协调机制，这样在同一时间只有一个线程对需要同步的代码块。互斥性页称作操作的原子性

2、可见性：必须确保在锁被释放之前，对共享变量所做的修改，对于随后获得该锁的另一个线程是可见的，否则另一个线程可能是本地缓存的某个副本上继续操作，从而引起不一致。

synchronized锁的不是代码，锁的都是对象。

### 根据获取的锁的分类：获取对象锁和获取类锁

获取对象锁的两种用法：

1、同步代码块(synchronized(this)，synchronized(类实例对象))，锁是小括号()中的实例对象

2、同步非静态方法，锁是当前对象的实例对象

获取类锁的两种方法：

1、同步代码块(synchronized(类.class))，锁是小括号（）中的类对象（Class对象）

2、同步静态方法，（synchronized static method），锁是当前对象的类对象

### 对象锁和类锁的总结

1、有线程访问对象的同步代码块，另外的线程可以访问该对象的非同步代码块

2、若锁住的是同一个对象，一个线程在访问对象的同步代码块时，另一个访问对象的同步代码块的线程会被阻塞

3、若锁住的是同一个对象，一个线程在访问对象的同步方法时，另一个访问对象同步方法的线程会被阻塞

4、若锁住的是同一个对象，一个线程在访问对象的同步代码块时，另一个访问对象同步方法的线程会被阻塞，反之亦然

5、同一个类的不同对象的对象锁互不干扰

6、类锁由于也是一中特殊的对象锁，因此表现和上述1，2，3，4一致，而由于一个类只能有一个对象锁，所以同一个类的不同对象使用类锁将会是同步的

7、类锁和对象锁互补干扰

### synchronized底层实现原理

#### 实现synchronized基础

1、java对象头

2、Monitor

#### 对象在内存中的布局

1、对象头 ，

结构包括 Mark Word ， Class Metadata Address

Mark Word 包括hashCode，分代年龄，锁类型等信息，重量级锁（指针指向的是monitor的起始地址，synchronized锁）

Class Metadata Address  类型指针指向对象的类元数据，jvm通过这个指针确定该对象是哪个类的数据

2、实例数据

3、对齐填充

### monitor

每个java对象天生自带一把看不见的锁

### synchronized是可重入锁

什么是重入

从互斥锁的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但是当一个线程再次请求自己持有对象锁的资源时，这种情况属于重入

### synchronized的优化

#### 自旋锁   PreBlockSpin

许多情况下，共享数据的锁定状态持续时间短，切换线程不值得

通过让线程执行忙循环等待锁的释放，不让出CPU

缺点：若锁被其他线程长时间占用，会带来许多性能上的开销

#### 自适应自旋锁

1、自旋的次数不再固定

2、由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定

#### 锁消除

**优化**

编译时，对上下文进行扫描，去除不可能存在竞争的锁

#### 锁粗化

**另一种极端**

扩大加锁的范围，避免反复加锁和解锁

### synchronized的四种状态

无锁  偏向锁 轻量级锁 重量级锁

**锁降级**

**锁膨胀**

##### 偏向锁

减少同一线程获取锁的代价

大多数情况下，锁不存在多线程竞争，总是同一个线程多次获得

核心思想：

如果一个线程获得了锁，那么锁就进入偏向模式，此时mark word的结构也变为偏向锁，当该线程再次请求锁时，无需再做任何同步操作，即获取锁的过程只需要检查mark word的锁标记以及当前线程id等于mark word的threadid即可，这样就省去了大量有关锁的申请操作

不适合锁竞争激烈的场合

##### 轻量锁

轻量级锁是偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量锁

适用的场景：线程交替执行同步块

若存在同一时间访问同一锁的情况，就会导致轻量锁膨胀为重量锁

##### 重量级锁

使用场景：同步块执行时间较长的场景



# ReentrantLock（再入锁）

  位于java.util.concurrent.locks包

基于AQS实现

能够实现比synchronized更细粒度的控制，如fairness

调用lock后必须用unlock

性能未必比synchronized高，并且也是可重入的



##### 公平性设置

ReentrantLock fair = new ReentrantLock(true)

参数为true时，倾向于将锁赋予等待时间最久的线程

公平锁，获取锁的顺序按先后调用lock方法的顺序

非公平锁：抢占顺序不一定

synchronized是非公平锁



##### ReentrantLock将锁对象化

判断是否有线程在排队等待获取锁

带超时的获取锁的尝试

感知有没有成功获取锁 



##### wait、notify notifyAll  Condition



### 读写锁和copyOnWrite

读写锁和copyOnWrite都适用于读多写少的情况

#### 读写锁（ReentrantReadWriteLock）

读写锁是一种特殊的自旋锁，它把对共享资源对访问者划分成了读者和写者，读者只对共享资源进行访问，写者则是对共享资源进行写操作。读写锁在ReentrantLock上进行了拓展使得该锁更适合读操作远远大于写操作对场景。一个读写锁同时只能存在一个写锁但是可以存在多个读锁，但不能同时存在写锁和读锁。

#### copyOnWrite

除了加锁之外有没有其他方法来保证线程安全。楼下很多回答copyonwrite机制

和单词描述的一样，他的实现就是写时复制， 在往集合中添加数据的时候，先拷贝存储的数组，然后添加元素到拷贝好的数组中，然后用现在的数组去替换成员变量的数组（就是get等读取操作读取的数组）。这个机制和读写锁是一样的，但是比读写锁有改进的地方，那就是读取的时候可以写入的 ，这样省去了读写之间的竞争，看了这个过程，你也发现了问题，同时写入的时候怎么办呢，当然果断还是加锁。

java中提供了两个利用这个机制实现的线程安全集合。copyonwritearraylist，copyonwritearrayset。看名字就大概猜到他们之间的关系，copyonwritearrayset的底层实现是copyonwritearraylist。

### AQS  是ReentantLock的底层

### Q:谈谈对于AQS的理解

#### 1、概念

AQS  abstractQueuedSynchronizer    抽象队列 同步器

定义了一套多线程访问共享资源的同步器框架，许多同步器的实现都依赖于它，如常用的ReentrantLock Semaphore

#### 2、框架

它维护了一个volatile的int型变量state（代表共享资源）和一个fifo线程等待队列（多线程争用资源时会被阻塞进入此队列）。这里volatile是核心关键，保证了state的可见性

访问state的方式有三种

getState，setState以及compareAndSetState

AQS定义两种资源共享方式，Exclusive（独占，比如reentrantLock），和share（共享）

**自定义同步器在实现的时候只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护，AQS已经在底层实现好了**

主要需要实现的方法有

1 isHeldExclusively

2 tryAcquire

3 tryRelease

4 tryAcquireShared

5 tryReleaseShared

以ReentrantLock为例，state的初始化为0，表示未锁定的状态，A线程Lock时，会调用tryAcquire独占该锁，并将state+1，此后，其他线程再tryAcquire时就会失败，直到A线程unlock到state=0,为止，其他线程才有机会获获取锁，当然在锁释放前，A线程自己是可以重复获取这个锁的，这就是可重入的概念，但要注意，获取多少次就要释放多少次，这样才能保证state是能回到零状态

**比较重要的内部方法**

acquire  其实就是lock真正执行的方法

独占模式下线程获取共享资源的顶层入口，如果获取到资源，线程直接返回，否则进入等待队列，直到获取资源位置。

Node addWaiter（Node mode）此方法用于将线程加入到等待队列队尾

Node结点是对每一个访问同步代码的线程封装，其包含了需要同步的线程本身以及线程的状态。

是否被阻塞，是否等待唤醒，是否已经被取消等

##### ReentrantLock和synchronized的区别

总结：

1、ReentrantLock是类，synchroized关键字

2、ReentrantLock可以对获取锁的等待时间设置，避免死锁

3、ReentrantLock可以获取各种锁的信息

4、ReentrantLock可以灵活实现多路通知

机制  synchronized操作Mark word  ReentrantLock调用unsafe类的park方法

# 原子类

### AtomicInteger

两个主要的成员变量

```
private static final Unsafe unsafe = Unsafe.getUnsafe();
private volatile int value;
```

value被volatile修饰，用于提供线程之间的可见性。

Unsafe类用来执行CAS操作。

如果CAS更新失败，则会一直死循环等待，直到成功。

### LongAdder

内部维护一个Ceil数组，采用了分段锁的思想。

为什么LongAdder会比AtomicLong更高效了，唯一会制约AtomicLong高效的原因是高并发，高并发意味着CAS的失败几率更高， 重试次数更多，越多线程重试，CAS失败几率又越高，变成恶性循环，AtomicLong效率降低。 那怎么解决？** LongAdder给了我们一个非常容易想到的解决方案：减少并发，**将单一value的更新压力分担到多个value**中去，降低单个value的 “热度”，分段更新！！！**

 increment() 方法则是采用CAS的方式自增，如果更新失败，则会该线程相关的HashCode对象后，获取它的code变量 ，在Cells 数组中当先线程的HashCode对应的 索引位置，并将该位置的Cell 对象拿出来用CAS更新它的value值。

longValue()方法实际是sum方法，则是求所有ceil数组的和，取到累加值。  

# volatile 

### 指令重排序需要满足的条件

1、在单线程环境中不能改变程序运行的结果

2、存在数据依赖关系的不允许重排序

即时

**无法通过happens-before原则推导出来，才能进行指令的重排序**

### happens-before

在Java内存模型中，happens-before 应该翻译成：前一个操作的结果可以被后续的操作获取。讲白点就是前面一个操作把变量a赋值为1，那后面一个操作肯定能知道a已经变成了1。 

> 程序次序规则：在一个线程内一段代码的执行结果是有序的。就是还会指令重排，但是随便它怎么排，结果是按照我们代码的顺序生成的不会变！
>
> 管程锁定规则：就是无论是在单线程环境还是多线程环境，对于同一个锁来说，一个线程对这个锁解锁之后，另一个线程获取了这个锁都能看到前一个线程的操作结果！(管程是一种通用的同步原语，synchronized就是管程的实现）
>
> volatile变量规则：就是如果一个线程先去写一个volatile变量，然后一个线程去读这个变量，那么这个写操作的结果一定对读的这个线程可见。
>
> 线程启动规则：在主线程A执行过程中，启动子线程B，那么线程A在启动子线程B之前对共享变量的修改结果对线程B可见。
>
> 线程终止规则：在主线程A执行过程中，子线程B终止，那么线程B在终止之前对共享变量的修改结果在线程A中可见。
>
> 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程代码检测到中断事件的发生，可以通过Thread.interrupted()检测到是否发生中断。
>
> 传递规则：这个简单的，就是happens-before原则具有传递性，即A happens-before B ， B happens-before C，那么A happens-before C。
>
> 对象终结规则：这个也简单的，就是一个对象的初始化的完成，也就是构造函数执行的结束一定 happens-before它的finalize()方法。

### volatile ：jvm提供的轻量级同步机制

1、保证被volatile修饰的共享变量对所有线程总是可见的

2、禁止指令重排序优化



### volatile变量为何立即可见

当写一个volatile变量时，jmm会把该线程对应的工作内存中的共享变量值刷新到主内存中

当读取一个volatile变量时，jmm会把该线程对应的工作内存设置为无效



### volatile如何禁止重排优化

利用内存屏障

1、保证特定操作的执行顺序

2、保证某些变量的内存可见性

通过插入内存屏障指令禁止在内存屏障前后的指令执行排序优化

> 程序在运行时内存实际的访问顺序和程序代码编写的访问顺序不一定一致，这就是内存乱序访问。内存乱序访问行为出现的理由是为了提升程序运行时的性能。内存乱序访问主要发生在两个阶段：
>
> 1. 编译时，编译器优化导致内存乱序访问（指令重排）
> 2. 运行时，多 CPU 间交互引起内存乱序访问
>
> Memory Barrier 能够让 CPU 或编译器在内存访问上有序。一个 Memory Barrier 之前的内存访问操作必定先于其之后的完成。Memory Barrier 包括两类：

# java线程池

### 利用Executors创建不同的线程池满足不同场景的需求

1、newFixedThreadPool（int n）

指定工作线程数量的线程池

2、newCachedThreadPool（）

处理大量短时间工作任务的线程池

（1）试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程

（2）如果线程闲置的时间超过阈值，则会被终止并被移出缓存

（3）系统长时间闲置的时候，不会消耗资源

3、newSingleThreadExecutor（）

创建唯一的工作者线程来执行任务

4、newScheduledThreadPool

定时或周期性的工作调度

5、newWorkStealingPool

内部构建forkJoinPool，利用working-stealing算法，并行处理任务。

### 为什么要使用线程池子

1、降低资源消耗

2、提高线程的可管理性

### juc的三个executor接口

1、executor  运行新任务的简单接口，将任务提交和任务执行细节解耦

2、executorService  具备管理执行器和任务生命周期的方法，提交任务机制更完善

3、scheduledExecutorService  支持future和定期执行任务



### ThreadPoolExecutor的构造函数

1、corePoolSize  核心线程数量

2、maximumPoolSize 线程不够用时能够创建的最大线程数

3、workQueue  任务等待队列

4、keepAliveTime 存活时间

5、threadAFactory 创建 新线程，默认的是，Executors.defaultThreadFac

会使创建的线程具有相同的优先级，并且不是守护线程

### handler：线程饱和策列

1、AbortPolicy    直接抛出异常

2、CallerRunsPolicy   用调用者所在的线程来执行任务

3、DiscardOldestPolicy   丢弃队里中最靠前的任务，并执行当前任务

4、DiscardPolicy   直接丢弃任务

5、实现RejectedExecutionHandle接口的自定义handle

### 新任务提交execute执行后的判断

1、如果运行的线程少于corePoolSize，则创建新的线程来处理任务，即使线程池中的其他线程是空闲的

2、如果线程池中的线程数量大于等于corePoolSize且小于maximumPoolSize，则只有当workQueue满时才创建新的线程去处理任务

3、如果设置的corePooSize和maximun相同，则创建的线程池的大小是固定的，这时如果有新的任务提交，若workQueue未满，则将请求放入workQueue中，等待有空闲的线程去从workQueue中取任务并处理

4、如果运行的线程数量大于等于maximumPoolSize，这时如果workQueue已经满了，则通过handle所指定的策略来处理任务

### 线程池的状态

running  能接受新提交的任务，并且也能处理阻塞队列中的任务

shutdown  不再接受新提交的任务，但可以处理存量的任务

stop  不再接受新提交的任务，也不处理存量的任务

tidying  所有任务都终止

terminated  terminated()方法执行完后进入改状态

### 线程池大小选择

1、cpu密集（主要计算）  线程数=按照核数   （核数+1）

2、IO密集  线程数量 = CPU*（1+平均等待时间/平均工作时间）

### 对于query的选择，以及排队的策略

1、使用直接提交策略，SynchronousQueue

在添加元素后必须等待其他线程取走后才可以继续添加

所以使用SynchronousQueue的时候通常要求maximunPoolSize是无界的

对于使用SynchronousQueue的作用，在jdk中写的很清楚

此策略可以避免在处理可以具有内部依赖性的请求集时出现锁。

2、使用无界队列策略，linkedBlockingQueue

超过corePoolSize的线程将添加进队列，无限添加，所以MaxiMumPoolSize失效，

3、使用有界队列，使用arrayBlockingQueue

即是，先超过corePoolsize的部分放入，指定了大小的queue，如果，还放不下就创新线程，超过了maxPoolSize就报异常





### 拒绝服务策略

通过构造参数设置

当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有四种策略

1、AbortPolicy

丢弃任务并抛出异常

2、DiscardPolicy

也是丢弃任务，但是不抛出异常

3、DiscardOldestPolicy

丢弃队列最前面的任务，然后重新尝试执行任务

4、CallerRunsPolicy

由调用线程处理该任务



# CAS

### Q:什么是CAS

CAS是乐观锁的一种思路，假设对共享资源的访问没有冲突，线程可以不停执行，无需加锁，无需等待，一旦发现冲突，无锁策略则采用一种称为CAS的技术来保证线程执行的安全性，这项CAS技术就是无锁策略实现的关键。

Compare and Swap 即比较交换

工作流程：

包含三个参数，

V 表示要更新的变量

E 表示预期值

N 表示新值

如果V值等于E值，则将V的值设为N。若V和E不同，则说明已经有其他线程做了更新，则当前线程什么都不做，但可以选择重新读取该变量再尝试再次修改该变量，也可以放弃操作。

通俗的说，就是CAS操作需要我们提供一个期望值，当期望值和当前线程的变量值相同的时候，说明还没有线程修改该值，当前线程可以进行修改，也就是执行cas操作，但如果期望值与当前线程不符，则说明该值已经被其他线程修改了，此时不执行更新操作，但可以选择重新读取该变量再尝试其他修改该变量，也可以放弃操作、

由于无锁操作没有锁的存在，因此不可能出现死锁的情况，也就是说无锁操作天生免疫死锁。



### Unsafe类

CAS的操作执行依赖于Unsafe类的方法，注意Unsafe类中的所有方法都是Native的，主要功能是：

1、内存管理

2、变量的操作

#### 和CAS相关的API

compareAndSwapObject

compareAndSwapInt

park

unpark

将一个线程挂起是通过park方法实现的，调用park后，线程将一直阻塞到超时或是中断等条件出现，

unpark则是终止一个线程的挂起。

Atomic系列内部就是基于下述方法实现的



#### Atomic类的底层就是通过Unsafe实现的，思路是CAS



### CAS的ABA问题及其解决方法

当第一个线程执行CAS（V,E,U）操作，在获取到当前变量V，准备修改为新值U前，另外两个线程已连续修改了两次变量V的值，使得改值又恢复为旧值。

#### 解决方法

AtomicStampedReference类是一个带有时间戳的对象引用，在每次修改后，不仅会设置新值而且会对记录更改的时间记录。当这个类要设置对象值时，对象值以及时间戳都必须满足期望值才能写入成功。





