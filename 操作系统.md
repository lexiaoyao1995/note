# 操作系统

## 内存分配策略

静态存储 ：编译时确定每个数据目标在运行时的存储空间需求 

要求代码中不允许有可变数据存在，或是递归存在

栈式存储：数据区需求在编译时未知，运行时确定

堆式存储：数据区在编译时和运行时都无法确定

## 进程与线程

### 区别和联系

进程是资源分配的最小单位，线程是程序执行的最小单位

进程使用独立的数据空间，线程共享进程的数据空间

### 协程

**协程，英文Coroutines，是一种比线程更加轻量级的存在。**正如一个进程可以拥有多个线程一样，一个线程也可以拥有多个协程。

最重要的是，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。

这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。

### 进程之间通信

##### 共享内存

进程之间共享数据 通过共享内存的方式

> **共享内存**这个通信方式就可以很好着解决拷贝所消耗的时间了。系统加载一个进程的时候，分配给进程的内存并不是实际物理内存，而是虚拟内存空间。那么我们可以让两个进程各自拿出一块虚拟地址空间来，然后映射到相同的物理内存中，这样，两个进程虽然有着独立的虚拟内存空间，但有一部分却是映射到相同的物理内存，这就完成了内存共享机制了。
>
> 共享内存最大的问题是什么？没错，就是多进程竞争内存的问题，就像类似于我们平时说的**线程安全**问题。如何解决这个问题？这个时候我们的**信号量**就上场了。
>
> 信号量的本质就是一个计数器，用来实现进程之间的互斥与同步。例如信号量的初始值是 1，然后 a 进程来访问**内存1**的时候，我们就把信号量的值设为 0，然后进程b 也要来访问**内存1**的时候，看到信号量的值为 0 就知道已经有进程在访问**内存1**了，这个时候进程 b 就会访问不了**内存1**。所以说，信号量也是进程之间的一种通信方式。

##### socket

进程之间交换数据 通过socket方式

> 这个就是我们一直在用的进程间的通信方式了，如我们的微信APP跟微信服务器通信，其实就是使用的Socket套接字进行通信的。

https://blog.csdn.net/zhu923850241/article/details/87110168

##### 管道

经常有需求要将一个程序的输出交给另一个程序进行处理，也因此，管道应运而生了。

管道可以分为两类：匿名管道和命名管道。

常见的Linux命令 "|" 其实就是匿名管道，表示把一个进程的输出传输到另外一个进程，如：

```bash
echo "Happyjava" | awk -F 'j' '{print $2}'
# 输出 ava
```

另外，我们可以通过 mkfifo <pipename> 命令创建一个命名管道，如：

```shell
mkfifo pipe
```

##### 消息队列

主要用于同步数据块，是一个异步的过程

使用消息队列进行进程间通信，可能会收到数据块最大长度的限制约束等，这也是这种通信方式的缺点。如果频繁的发生进程间的通信行为，那么进程需要频繁地读取队列中的数据到内存，相当于间接地从一个进程拷贝到另一个进程，这需要花费时间。

##### 信号量

共享内存最大的问题是什么？没错，就是多进程竞争内存的问题，就像类似于我们平时说的**线程安全**问题。如何解决这个问题？这个时候我们的**信号量**就上场了。

信号量的本质就是一个计数器，用来实现进程之间的互斥与同步。例如信号量的初始值是 1，然后 a 进程来访问**内存1**的时候，我们就把信号量的值设为 0，然后进程b 也要来访问**内存1**的时候，看到信号量的值为 0 就知道已经有进程在访问**内存1**了，这个时候进程 b 就会访问不了**内存1**。所以说，信号量也是进程之间的一种通信方式。

### 线程间同步的方式

- 互斥量 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问
- 信号量 Semphare：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
- 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

### **进程同步**

1、临界区（Critical Section）:通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。

优点：保证在某一时刻只有一个线程能访问数据的简便办法

缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。

 

2、互斥量（Mutex）:为协调共同对一个共享资源的单独访问而设计的。

互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。

优点：使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。

缺点：①互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。

②通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号量对象可以说是一种资源计数器。

 

3、信号量（Semaphore）:为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。

优点：适用于对Socket（套接字）程序中线程的同步。（例如，网络上的HTTP服务器要对同一时间内访问同一页面的用户数加以限制，只有不大于设定的最大用户数目的线程能够进行访问，而其他的访问企图则被挂起，只有在有用户退出对此页面的访问后才有可能进入。）

缺点：①信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点；

②信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和维护都很困难，加重了程序员的编码负担；

③核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和纠正。

 

4、事件（Event）: 用来通知线程有一些事件已发生，从而启动后继任务的开始。

优点：事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程中的线程同步操作。

 

总结：

①临界区不是内核对象，只能用于进程内部的线程同步，是用户方式的同步。互斥、信号量是内核对象可以用于不同进程之间的线程同步（跨进程同步）。
②互斥其实是信号量的一种特殊形式。互斥可以保证在某一时刻只有一个线程可以拥有临界资源。信号量可以保证在某一时刻有指定数目的线程可以拥有临界资源。

### 线程调度

- FCFS(先来先服务，队列实现，非抢占的)：先请求CPU的进程先分配到CPU
- SJF(最短作业优先调度算法)：平均等待时间最短，但难以知道下一个CPU区间长度
- 优先级调度算法(可以是抢占的，也可以是非抢占的)：优先级越高越先分配到CPU，相同优先级先到先服务，存在的主要问题是：低优先级进程无穷等待CPU，会导致无穷阻塞或饥饿；解决方案：**老化**
- 时间片轮转调度算法(可抢占的)：队列中没有进程被分配超过一个时间片的CPU时间，除非它是唯一可运行的进程。如果进程的CPU区间超过了一个时间片，那么该进程就被抢占并放回就绪队列。
- 多级队列调度算法：将就绪队列分成多个独立的队列，每个队列都有自己的调度算法，队列之间采用固定优先级抢占调度。其中，一个进程根据自身属性被永久地分配到一个队列中。
- 多级反馈队列调度算法：与多级队列调度算法相比，其允许进程在队列之间移动：若进程使用过多CPU时间，那么它会被转移到更低的优先级队列；在较低优先级队列等待时间过长的进程会被转移到更高优先级队列，以防止饥饿发生。

### 线程切换步骤

线程上下文切换，线程切换代价

> 对于单核CPU来说（对于多核CPU，此处就理解为一个核），CPU在一个时刻只能运行一个线程，当在运行一个线程的过程中转去运行另外一个线程，这个叫做线程上下文切换（对于进程也是类似）。

> 线程切换时需要知道在这之前当前线程已经执行到哪条指令了，所以需要记录程序计数器的值，另外比如说线程正在进行某个计算的时候被挂起了，那么下次继续执行的时候需要知道之前挂起时变量的值时多少，因此需要记录CPU寄存器的状态。所以一般来说，线程上下文切换过程中会记录程序计数器、CPU寄存器状态等数据。

### **分页和分段**

　段式存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）

　页式存储管理方案是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的帧，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）。

***\*两者的不同点：\****

- 目的不同：分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息；
- 大小不同：页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定；
- 地址空间不同： 段向用户提供二维地址空间；页向用户提供的是一维地址空间；
- 信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制；
- 内存碎片：页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）；而段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）。

### **虚拟内存**

虚拟内存允许执行进程不必完全在内存中。虚拟内存的基本思想是：每个进程拥有独立的地址空间，这个空间被分为大小相等的多个块，称为页(Page)，每个页都是一段连续的地址。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻进行必要的映射；当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的命令。这样，**对于进程而言，逻辑上似乎有很大的内存空间，实际上其中一部分对应物理内存上的一块(称为帧，通常页和帧大小相等)，还有一些没加载在内存中的对应在硬盘上，如图5所示。**
注意，请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。

![](https://img-blog.csdn.net/20171021161259614?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvanVzdGxvdmV5b3Vf/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

　由图5可以看出，虚拟内存实际上可以比物理内存大。当访问虚拟内存时，会访问MMU（内存管理单元）去匹配对应的物理地址（比如图5的0，1，2）。如果虚拟内存的页并不存在于物理内存中（如图5的3,4），会产生缺页中断，从磁盘中取得缺的页放入内存，如果内存已满，还会根据某种算法将磁盘中的页换出。

------

3). 页面置换算法

- FIFO先进先出算法：在操作系统中经常被用到，比如作业调度（主要实现简单，很容易想到）；
- LRU（Least recently use）最近最少使用算法：根据使用时间到现在的长短来判断；
- LFU（Least frequently use）最少使用次数算法：根据使用次数来判断；
- OPT（Optimal replacement）最优置换算法：理论的最优，理论；就是要保证置换出去的是不再被使用的页，或者是在实际内存中最晚使用的算法。

------

4). 虚拟内存的应用与优点

　　虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。虚拟内存的使用可以带来以下好处：

- 在内存中可以保留多个进程，系统并发度提高
- 解除了用户与内存之间的紧密约束，进程可以比内存的全部空间还大

### **颠簸**

　颠簸本质上是指频繁的页调度行为，具体来讲，进程发生缺页中断，这时，必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此，会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸（抖动）。

　　内存颠簸的解决策略包括：

- 如果是因为页面替换策略失误，可以修改替换算法来解决这个问题；
- 如果是因为运行的程序太多，造成程序无法同时将所有频繁访问的页面调入内存，则要降低多道程序的数量；
- 否则，还剩下两个办法：终止该进程或增加物理内存容量。

### **局部性原理**

(1). 时间上的局部性：最近被访问的页在不久的将来还会被访问；

(2). 空间上的局部性：内存中被访问的页周围的页也很可能被访问。

### 分页机制

http://www.imooc.com/article/11015



### fork

​    一个进程，包括代码、数据和分配给进程的资源。fork（）函数通过系统调用创建一个与原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。
​    一个进程调用fork（）函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。相当于克隆了一个自己。

fork调用的一个奇妙之处就是它仅仅被调用一次，却能够返回两次，它可能有三种不同的返回值：
    1）在父进程中，fork返回新创建子进程的进程ID；
    2）在子进程中，fork返回0；
    3）如果出现错误，fork返回一个负值；

​    在fork函数执行完毕后，如果创建新进程成功，则出现两个进程，一个是子进程，一个是父进程。在子进程中，fork函数返回0，在父进程中，fork返回新创建子进程的进程ID。我们可以通过fork返回的值来判断当前进程是子进程还是父进程。

### 为什么线程调度比进程调度开销小

#### 进程与线程的差异

从概念上来讲，线程是进程的一部分，只是任务调度相关的部分，所以我们才说，“线程是调度的最小单位”。进程拥有着资源，这些资源不属于某一个特定线程，因为所有线程共享进程拥有的资源，所以我们才说，“进程是资源分配的最小单位”。需要特别说明的是，Linux在线程与进程的实现上与概念上有少许差别，这个等下再讨论。

所以，我们fork一个新的进程时，实际上“伴生”了一个线程，而这个唯一的线程，实际上代表了这个进程参与到任务调度。在执行的过程中，进程通过pthread_create创建了更多的线程，例如上图中的线程2，线程n。此时，不管线程1，线程2，还是线程n，他们都代表了进程进行任务调度。

既然我们知道了进程与线程有什么关系，那么实际的linux内核是怎么实现进程与线程的呢？

在linux中，不管进程还是线程，都用struct task_struct描述。

~~~shell
struct task_struct {
	...
	struct mm_struct *mm; /*内存资源*/
	...
}
~~~

既然都是用struct task_struct描述，那么进程和线程的关系怎么体现？资源指针！例如上面代码块描述的结构成员struct mm_struct *mm，这是一个指针，指向实际的内存资源。同一个进程内的所有线程，他们都使用相同的资源，只需要把对应的资源指针指向相同的地址。

Linux内核就好像淡化了“线程”的概念，每一个线程描述都是struct task_struct，他们都是一个独立的“进程”，都有着自己的进程号，都参与任务调度，只不过指向相同的进程资源。

#### 任务调度的开销
既然我们知道了进程和线程在linux实现上的关系，我们再来分析，为什么说线程调度比进程调度开销更小？

或许你有这样的疑问，既然在linux实现上，线程都是独立的struct task_struct，都参与任务调度，那这里说的线程调度和进程调度怎么区分？

我们不妨这样定义：

**线程调度：使用相同资源的`struct task_struct`之间的调度**
**进程调度：使用不同资源的`struct task_struct`之间的调度**

基于这样的定义，为了方便分析问题，我们回顾一下任务调度的开销主要有什么？

1. **CPU执行任务调度的开销，主要是进程上下文切换的开销**
2. **任务调度后，CPU Cache/TLB不命中，导致缺页中断的开销**

对于第1点的开销，不管是进程调度还是线程调度都是必须的，所以，两者的差异体现在第2点。

再看回我们对“进程调度”和“线程调度”的定义，有没觉得灵光一闪？既然线程调度的struct task_struct都使用相同的资源，是不是就意味着，我即使切换到了其他的线程，**CPU Cache/TLB命中的概率会高很多**？相反，进程调度使用的是不同的资源，每次换了个进程，就意味着原有的Cache就不适用了，没命中，就触发更多的缺页中断，开销自然就更多。

## 网络通信

**程序的网络通信依赖于操作系统的网络通信**

程序不能直接访问内核，用户程序想要调用内核的方法，需要使用`int 80`中断，CPU从用户态切换到内核态。操作系统给内核暴露了几百个系统调用`syscall`。

首先需要了解操作系统的关于网络io的系统函数中哪些是可能阻塞的。

- socket
  创建一个socket对象，并返回其文件描述符

- bind
  绑定一个socket和对应的端口号

- listen
  socket开始监听

- **accept**
  socket，服务器端等待客户端的连接，（阻塞）

- **recv**

  客户端已经已经连接上，从客户端读取数据（阻塞）

### BIO

由于，函数accept和recv两个过程都是阻塞的，阻塞IO的实现思路为：主线程负责接受客户端，即阻塞执行accept，然后开启子线程去执行recv。

BIO的实质就是一个线程负责处理一个连接，如果是连接比较少，而且每个连接需要频繁进行通信的场景下适用，但是如果连接数太大，则需要在服务器端创建过多线程，导致cpu需要频繁切换线程，而且容易造成内存溢出。

### NIO

为了解决BIO的问题，在操作系统内核函数优化，有了非阻塞的socket，通过设置SOCK_NONBLOCK为开启，默认情况下是阻塞的。此时accept函数就是非阻塞的了，如果有客户端连接上，则返回当前连接的客户端的文件操作符，如果没有返回则立即返回-1。

通过客户端也可以设置为非阻塞的，则recv函数则会变为非阻塞的，如果有数据写入，则返回数据，否则返回-1 。

所以NIO的思路为：

通过主线程死循环去执行accept方法，如果不为-1，则将其文件描述符加入队列。

每次循环中同时**遍历**队列，执行recv方法

通过采用NIO方式则不用在操作系统中不断创建新的线程。

#### 缺陷

C10K当并发量很大的时候，文件描述符会很多，每循环一次，都要调用一次recv系统调用（复杂度`O(n)`），进行用户态到内核态的切换，切换时性能损耗大。

当C10K只有1个C发来了数据，只使用到了1个有用的系统调用，剩余n-1次的监听都是无效的->技术选型失败。（架构师进行技术选型：要懂原理）

> C10K问题
>
> 一台服务器连接10K个客户端
>
> 由于C10K问题的出现，推进了网络IO的发展

#### 改进

只有当这个客户端有输入的时候，服务器端才去执行recv方法，即是筛选出需要recv的文件描述符

### 多路复用

为了解决NIO的多次进行系统调用的问题，所以有了多路复用的出现，主要思想是：通过一条指令让用户态程序感知到哪个socket的文件描述符有输入，这样就进行点对点的调用recv。

#### select/poll

select和poll，都是内核程序，入参位fds（多个文件描述符），出参为有输入的fd

然后用户程序更具这个fd来进行调用recv程序。

> select和poll的区别
>
> poll使用pollfd结构而不是select的fd_set结构.
>
> select只能接受1024个fds
>
> poll可配

##### 缺陷

采用select和poll的本质其实也是遍历，但是是在内核里的遍历，对于用户态程序来说，只是一次系统调用。

并且每次select和poll的入参都是全部的文件描述符，在用户空间和内核空间来回拷贝。

#### epoll

epoll就是为了解决select和poll的以上两个缺陷。

epoll在主要依赖于计算机组成里DMA，将网络数据直接写入DMA，然后通过中断，产生回调事件，通知cpu哪个socket有数据进来。所以就解决了select和poll的遍历问题。

对于select的文件描述符的来回拷贝，epoll在内核中开辟一块内存空间来保存这些文件描述符，所以就不需要传输全量的fds，只需传输增量。

epoll在被内核初始化时（操作系统启动），同时会开辟出epoll自己的内核高速cache区，用于安置每一个我们想监控的socket，这些socket会以红黑树的形式保存在内核cache里，以支持快速的查找、插入、删除。这个内核高速cache区，就是建立连续的物理内存页，然后在之上建立slab层，简单的说，就是物理上分配好你想要的size的内存对象，每次使用时都是使用空闲的已分配好的对象。

> DMA直接存储器访问
>
> 在ＤＭＡ出现之前，CPU与外设之间的数据传送方式有程序传送方式、中断传送方式。CPU是通过系统总线与其他部件连接并进行数据传输。
>
> 允许不同速度的硬件装置来沟通，而不需要依赖于CPU的大量中断负载。
>
> 外设（网卡）可以直接把数据写入DMA中

##### 内核程序

epoll主要包含以下几种内核函数：

* epoll_create

在内核中开辟epoll的空间用于存放fd

* epoll_ctl

将fd注册到epoll_create创建的空间中，（epoll_add/epoll_del的合体），往epoll对象中增加/删除某一个流的某一个事件

* eoll_wait

等待刚才的注册的fd产生事件

### AIO

AIO希望的是，你select，poll，epoll都需要用一个函数去监控一大堆fd，那么我AIO不需要了，你把fd告诉内核，你应用程序无需等待，内核会通过信号等软中断告诉应用程序，数据来了，你直接读了，所以，用了AIO可以废弃select，poll，epoll。

##### linux

 linux的AIO的实现方式是内核和应用共享一片内存区域，应用通过检测这个内存区域（避免调用nonblocking的read、write函数来测试是否来数据，因为即便调用nonblocking的read和write由于进程要切换用户态和内核态，仍旧效率不高）来得知fd是否有数据，可是检测内存区域毕竟不是实时的，你需要在线程里构造一个监控内存的循环，设置sleep，总的效率不如epoll这样的实时通知。所以，AIO是渣，适合低并发的IO操作。所以java7引入的NIO.2引入的AIO对高并发的网络IO设计程序来说，也是渣，只有Netty的epoll+edge-triggered notification最牛，能在linux让应用和OS取得最高效率的沟通。

##### WIndows的IOCP

I/O Completion Port

IOCP完成端口是Windows下性能最好的I/O模型，同时它也是最复杂的内核对象。

一共包括三部分：完成端口（存放重叠的I/O请求），客户端请求的处理，等待者线程队列（一定数量的工作者线程，一般采用CPU*2个）

完成端口其实就是一个通知队列，由操作系统把已经完成的重叠I/O请求的通知放入其中。当某项I/O操作一旦完成，某个可以对该操作结果进行处理的工作者线程就会收到一则通知。

**优势**

基于IOCP的开发是异步IO的，决定了IOCP所实现的服务器的高吞吐量。

　　通过引入IOCP，会大大减少Thread切换带来的额外开销，最小化的线程上下文切换，减少线程切换带来的巨大开销，让CPU把大量的事件用于线程的运行。当与该完成端口相关联的可运行线程的总数目达到了该并发量，系统就会阻塞，

### 三种io的使用场景

BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。

NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。

AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。



## 用户态和内核态

### 特权级

对于任何操作系统来说，创建一个进程是核心功能。创建进程要做很多工作，会消耗很多物理资源。比如分配物理内存，父子进程拷贝信息，拷贝设置页目录页表等等，这些工作得由特定的进程去做，所以就有了特权级别的概念。最关键的工作必须交给特权级最高的进程去执行，这样可以做到集中管理，减少有限资源的访问和使用冲突。inter x86架构的cpu一共有四个级别，0-3级，0级特权级最高，3级特权级最低。

### 用户态和内核态的概念：

当一个进程在执行用户自己的代码时处于用户运行态（用户态），此时特权级最低，为3级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态。Ring3状态不能访问Ring0的地址空间，包括代码和数据；当一个进程因为系统调用陷入内核代码中执行时处于内核运行态（内核态），此时特权级最高，为0级。执行的内核代码会使用当前进程的内核栈，每个进程都有自己的内核栈。

用户运行一个程序，该程序创建的进程开始时运行自己的代码，处于用户态。如果要执行文件操作、网络数据发送等操作必须通过write、send等系统调用，这些系统调用会调用内核的代码。进程会切换到Ring0，然后进入3G-4G中的内核地址空间去执行内核代码来完成相应的操作。内核态的进程执行完后又会切换到Ring3，回到用户态。这样，用户态的程序就不能随意操作内核地址空间，具有一定的安全保护作用。这说的保护模式是指通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程地址空间中的数据。

### 用户态和内核态的切换

当在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成一些用户态自己没有特权和能力完成的操作时就会切换到内核态。

用户态切换到内核态的3种方式

#### （1）系统调用

这是用户态进程主动要求切换到内核态的一种方式。用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。例如fork（）就是执行了一个创建新进程的系统调用。系统调用的机制和新是使用了操作系统为用户特别开放的一个中断来实现，如Linux的int 80h中断。

#### （2）异常

当cpu在执行运行在用户态下的程序时，发生了一些没有预知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到了内核态，如缺页异常。

#### （3）外围设备的中断

当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令而转到与中断信号对应的处理程序去执行，如果前面执行的指令时用户态下的程序，那么转换的过程自然就会是 由用户态到内核态的切换。如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。

这三种方式是系统在运行时由用户态切换到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。从触发方式上看，切换方式都不一样，但从最终实际完成由用户态到内核态的切换操作来看，步骤有事一样的，都相当于执行了一个中断响应的过程。系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本一致。

### 用户态到内核态具体的切换步骤：

（1）从当前进程的描述符中提取其内核栈的ss0及esp0信息。

（2）使用ss0和esp0指向的内核栈将当前进程的cs,eip,eflags,ss,esp信息保存起来，这个过程也完成了由用户栈到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。

（3）将先前由中断向量检索得到的中断处理程序的cs,eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。



# 死锁

## 四个基本条件

```
1、互斥：某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结束。
2、占有且等待：一个进程本身占有资源（一种或多种），同时还有资源未得到满足，正在等待其他进程释放该资源。
3、不可抢占：别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来。
4、循环等待：存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源。
   当以上四个条件均满足，必然会造成死锁，发生死锁的进程无法进行下去，它们所持有的资源也无法释放。这样会导致CPU的吞吐量下降。所以死锁情况是会浪费系统资源和影响计算机的使用性能的。那么，解决死锁问题就是相当有必要的了。
```

## 应对死锁

### 死锁预防

 产生死锁需要四个条件，那么，只要这四个条件中至少有一个条件得不到满足，就不可能发生死锁了。由于互斥条件是非共享资源所必须的，不仅不能改变，还应加以保证，所以，主要是破坏产生死锁的其他三个条件。

a、破坏“占有且等待”条件
     方法1：所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源。
         优点：简单易实施且安全。
         缺点：因为某项资源不满足，进程无法启动，而其他已经满足了的资源也不会得到利用，严重降低了资源的利用率，造成资源浪费。使进程经常发生饥饿现象。
     方法2：该方法是对第一种方法的改进，允许进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放掉分配到的已经使用完毕的资源，然后再去请求新的资源。这样的话，资源的利用率会得到提高，也会减少进程的饥饿问题。
b、破坏“不可抢占”条件
      当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请。这就意味着进程已占有的资源会被短暂地释放或者说是被抢占了。
      该种方法实现起来比较复杂，且代价也比较大。释放已经保持的资源很有可能会导致进程之前的工作实效等，反复的申请和释放资源会导致进程的执行被无限的推迟，这不仅会延长进程的周转周期，还会影响系统的吞吐量。
c、破坏“循环等待”条件
     可以通过定义资源类型的线性顺序来预防，可将每个资源编号，当一个进程占有编号为i的资源时，那么它下一次申请资源只能申请编号大于i的资源。

### 避免死锁

死锁避免是利用额外的检验信息，在分配资源时判断是否会出现死锁，只在不会出现死锁的情况下才分配资源。

两种避免办法：

​    1、如果一个进程的请求会导致死锁，则不启动该进程

​    2、如果一个进程的增加资源请求会导致死锁 ，则拒绝该申请。

避免死锁的具体实现通常利用银行家算法

**银行家算法**通过对进程需求、占有和系统拥有资源的实时统计，确保系统在分配给进程资源不会造成死锁才会给与分配。

> 银行家算法
>
> 银行家算法是一种最有代表性的避免死锁的算法。在避免死锁方法中允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配资源的安全性，若分配不会导致系统进入不安全状态，则分配，否则等待。
>
> 
>
> 银行家算法在避免死锁角度上非常有效，**但是**需要在进程运行前就知道其所需资源的最大值，且进程数也通常不是固定的，因此使用有限，但从思想上可以提供了解，可以转换地应用在其他地方



死锁避免的优点：不需要死锁预防中的抢占和重新运行进程，并且比死锁预防的限制要少。
死锁避免的限制：

* 必须事先声明每个进程请求的最大资源量
* 考虑的进程必须无关的，也就是说，它们执行的顺序必须没有任何同步要求的限制
* 分配的资源数目必须是固定的。
* 在占有资源时，进程不能退出



### 死锁检测与解除

如果利用死锁检测算法检测出系统已经出现了死锁 ，那么，此时就需要对系统采取相应的措施。常用的解除死锁的方法：

1、抢占资源：从一个或多个进程中抢占足够数量的资源分配给死锁进程，以解除死锁状态。

2、终止（或撤销）进程：终止或撤销系统中的一个或多个死锁进程，直至打破死锁状态。

